import{_ as i,c as a,o as n,ah as l}from"./chunks/framework.Bb6kz8E2.js";const g=JSON.parse('{"title":"로봇에서 NPU 사용하기","description":"","frontmatter":{},"headers":[],"relativePath":"ai-app/basic.md","filePath":"ai-app/basic.md"}'),t={name:"ai-app/basic.md"};function h(e,s,k,p,r,o){return n(),a("div",null,[...s[0]||(s[0]=[l(`<h1 id="로봇에서-npu-사용하기" tabindex="-1">로봇에서 NPU 사용하기 <a class="header-anchor" href="#로봇에서-npu-사용하기" aria-label="Permalink to “로봇에서 NPU 사용하기”">​</a></h1><p>Mini Pi는 RK3588s CPU를 사용하고 있으며 NPU를 내장하고 있습니다. CPU에 내장된 NPU를 사용하기 위해서는 <strong>RKNN-Toolkit2</strong>와 <strong>rknn-toolkit-lite2</strong>을 사용해야 합니다.</p><p><strong>RKNN-Toolkit2</strong>는 PC(Ubuntu 등)에서 딥러닝 모델(ONNX, PyTorch, TensorFlow 등)을 Rockchip NPU용 포맷(<code>.rknn</code>)으로 변환하고, 시뮬레이션 및 성능 분석을 수행하는 도구입니다.</p><h2 id="_1-개요-및-환경-구축" tabindex="-1">1. 개요 및 환경 구축 <a class="header-anchor" href="#_1-개요-및-환경-구축" aria-label="Permalink to “1. 개요 및 환경 구축”">​</a></h2><h3 id="_1-1-대상-하드웨어" tabindex="-1">1.1 대상 하드웨어 <a class="header-anchor" href="#_1-1-대상-하드웨어" aria-label="Permalink to “1.1 대상 하드웨어”">​</a></h3><p>RKNN-Toolkit2는 다음 칩셋을 지원합니다. (구형 칩셋인 RK3399Pro 등은 Toolkit1을 써야 하므로 주의하세요.)</p><ul><li><strong>RK3588 / RK3588S</strong> (가장 대중적)</li><li><strong>RK3568, RK3566, RK3562</strong></li><li><strong>RV1103, RV1106</strong></li></ul><h3 id="_1-2-설치-방법-pc-ubuntu-권장" tabindex="-1">1.2 설치 방법 (PC - Ubuntu 권장) <a class="header-anchor" href="#_1-2-설치-방법-pc-ubuntu-권장" aria-label="Permalink to “1.2 설치 방법 (PC - Ubuntu 권장)”">​</a></h3><p>가장 추천하는 방법은 <strong>Conda(Miniconda)</strong> 가상환경을 사용하는 것입니다.</p><ol><li><p><strong>소스코드 다운로드</strong></p><div class="language-bash"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">git</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> clone</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> https://github.com/ai-rockchip/rknn-toolkit2.git</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">cd</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> rknn-toolkit2</span></span></code></pre></div></li><li><p><strong>Conda 환경 생성 (Python 3.8 권장)</strong></p><div class="language-bash"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">conda</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> create</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> rknn</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> python=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3.8</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">conda</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> activate</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> rknn</span></span></code></pre></div></li><li><p><strong>의존성 라이브러리 설치</strong></p><div class="language-bash"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># rknn-toolkit2/doc/requirements_cp38-*.txt 파일을 사용</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -r</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> doc/requirements_cp38-1.6.0.txt</span></span></code></pre></div></li><li><p><strong>Toolkit 설치</strong><code>packages</code> 폴더로 이동하여 본인 환경(x86_64 리눅스)에 맞는 whl 설치</p><div class="language-bash"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> packages/rknn_toolkit2-x.x.x-cp38-cp38-linux_x86_64.whl</span></span></code></pre></div></li></ol><h2 id="_2-핵심-워크플로우-the-5-steps" tabindex="-1">2. 핵심 워크플로우 (The 5 Steps) <a class="header-anchor" href="#_2-핵심-워크플로우-the-5-steps" aria-label="Permalink to “2. 핵심 워크플로우 (The 5 Steps)”">​</a></h2><p>모델 변환 코드는 항상 아래 <strong>5단계</strong> 구조를 따릅니다.</p><ol><li><strong>RKNN 객체 생성</strong>: 도구 초기화</li><li><strong>Config (설정)</strong>: 타겟 칩셋(RK3588 등)과 전처리 옵션 설정</li><li><strong>Load (로드)</strong>: 원본 모델(ONNX 등) 불러오기</li><li><strong>Build (빌드)</strong>: NPU용으로 컴파일 및 양자화 수행</li><li><strong>Export (저장)</strong>: <code>.rknn</code> 파일로 저장</li></ol><h2 id="_3-실전-예제-yolo-onnx-변환-코드" tabindex="-1">3. 실전 예제: YOLO(ONNX) 변환 코드 <a class="header-anchor" href="#_3-실전-예제-yolo-onnx-변환-코드" aria-label="Permalink to “3. 실전 예제: YOLO(ONNX) 변환 코드”">​</a></h2><p><code>convert_yolo.py</code> 파일을 만들고 아래 내용을 작성합니다.</p><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sys</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> rknn.api </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> RKNN</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 1. 경로 설정</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">ONNX_MODEL</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;yolov5s.onnx&#39;</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">   # 변환할 ONNX 모델</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">RKNN_MODEL</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;yolov5s.rknn&#39;</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">   # 저장될 RKNN 파일명</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">DATASET</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;./dataset.txt&#39;</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">     # 양자화 보정용 이미지 경로 리스트 파일</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __name__</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> ==</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;__main__&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Step 1: RKNN 객체 생성</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    rknn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> RKNN(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">verbose</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Step 2: 설정 (Config)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # target_platform: 사용할 보드의 칩셋명 (rk3588, rk3568 등)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # optimization_level: 3이 최고 성능</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;--&gt; Config model&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    rknn.config(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">mean_values</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">std_values</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">255</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">255</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">255</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">target_platform</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;rk3588&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Step 3: 모델 로드 (Load ONNX)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;--&gt; Loading model&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ret </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> rknn.load_onnx(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">ONNX_MODEL</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ret </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">!=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Load model failed!&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        sys.exit(ret)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Step 4: 빌드 (Build)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # do_quantization=True: i8 양자화 사용 (속도 빠름, 정확도 약간 하락)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # dataset: 양자화 시 데이터 분포를 파악하기 위한 샘플 이미지 리스트</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;--&gt; Building model&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ret </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> rknn.build(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">do_quantization</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dataset</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">DATASET</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ret </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">!=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Build model failed!&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        sys.exit(ret)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Step 5: 내보내기 (Export)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;--&gt; Export rknn model&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ret </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> rknn.export_rknn(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">RKNN_MODEL</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ret </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">!=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Export rknn model failed!&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        sys.exit(ret)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;done&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><h2 id="_4-api-상세-설명-및-중요-팁" tabindex="-1">4. API 상세 설명 및 중요 팁 <a class="header-anchor" href="#_4-api-상세-설명-및-중요-팁" aria-label="Permalink to “4. API 상세 설명 및 중요 팁”">​</a></h2><h3 id="_4-1-rknn-config" tabindex="-1">4.1 <code>rknn.config()</code> <a class="header-anchor" href="#_4-1-rknn-config" aria-label="Permalink to “4.1 rknn.config()”">​</a></h3><p>가장 중요한 설정 함수입니다. 여기서 전처리(Normalization)를 NPU 내부에서 처리하도록 설정할 수 있습니다.</p><ul><li><code>mean_values</code>, <code>std_values</code>: <strong>매우 중요</strong>. <ul><li>YOLO 학습 시 보통 이미지를 0~255로 읽어서 0~1로 나누어 학습합니다 (<code>img / 255.0</code>).</li><li>이 연산을 NPU가 하도록 하려면 <code>mean=[0,0,0]</code>, <code>std=[255,255,255]</code>로 설정해야 합니다.</li><li>이렇게 하면 입력으로 들어오는 <code>raw image (0~255)</code>를 NPU가 알아서 <code>(x - 0) / 255</code> 처리합니다.</li></ul></li><li><code>target_platform</code>: <code>rk3588</code>, <code>rk3568</code> 등 정확히 기입해야 합니다.</li></ul><h3 id="_4-2-rknn-build" tabindex="-1">4.2 <code>rknn.build()</code> <a class="header-anchor" href="#_4-2-rknn-build" aria-label="Permalink to “4.2 rknn.build()”">​</a></h3><p>실질적인 컴파일 단계입니다.</p><ul><li><code>do_quantization</code>: <code>True</code>로 설정하면 <strong>INT8(정수) 연산</strong>으로 변환합니다. NPU는 INT8에서 가장 강력한 성능을 냅니다. <code>False</code>면 FP16(부동소수점)으로 동작하며, 속도가 느려질 수 있습니다.</li><li><code>dataset</code>: 양자화를 하려면 &quot;이 모델이 다루는 이미지의 분포&quot;를 알아야 합니다. 이를 위해 샘플 이미지(약 10~50장)의 경로가 적힌 텍스트 파일(<code>dataset.txt</code>)을 넣어줘야 합니다.</li></ul><h2 id="_5-양자화-quantization-를-위한-dataset-txt-만들기" tabindex="-1">5. 양자화(Quantization)를 위한 dataset.txt 만들기 <a class="header-anchor" href="#_5-양자화-quantization-를-위한-dataset-txt-만들기" aria-label="Permalink to “5. 양자화(Quantization)를 위한 dataset.txt 만들기”">​</a></h2><p>양자화(<code>do_quantization=True</code>)를 사용하려면 <code>dataset.txt</code>가 필수입니다.</p><ol><li>프로젝트 폴더에 <code>subset</code> 폴더를 만들고 테스트용 이미지 10장 정도를 넣습니다.</li><li><code>dataset.txt</code> 파일을 만들고 이미지 경로를 적습니다.</li></ol><p><strong>dataset.txt 예시:</strong></p><div class="language-text"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span>./subset/image_01.jpg</span></span>
<span class="line"><span>./subset/image_02.jpg</span></span>
<span class="line"><span>...</span></span></code></pre></div><div class="info custom-block"><p class="custom-block-title">왜 필요한가요?</p><p>FP32(소수점) 값을 INT8(정수 -128 ~ 127)로 매핑하려면, 데이터 값의 범위(최소값, 최대값)를 알아야 합니다. 툴킷은 이 샘플 이미지들을 모델에 통과시켜 각 레이어의 활성화 값 분포를 분석(Calibration)하여 최적의 변환 계수를 찾습니다.</p></div><h2 id="_6-자주-겪는-문제-troubleshooting" tabindex="-1">6. 자주 겪는 문제 (Troubleshooting) <a class="header-anchor" href="#_6-자주-겪는-문제-troubleshooting" aria-label="Permalink to “6. 자주 겪는 문제 (Troubleshooting)”">​</a></h2><ol><li><p><strong>ONNX Version 문제</strong></p><ul><li>YOLO 모델을 ONNX로 내보낼 때 <code>opset=12</code>를 권장합니다.</li><li>너무 최신 버전(opset 17 등)은 RKNN이 아직 지원하지 않을 수 있습니다.</li></ul></li><li><p><strong>ONNX Simplifier 필수</strong></p><ul><li>YOLO 모델 구조는 복잡합니다. 반드시 <code>onnx-simplifier</code>를 돌린 후 변환하세요.</li><li><div class="language-bash"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> onnx-simplifier</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">python3</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -m</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> onnxsim</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> yolov5s.onnx</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> yolov5s_sim.onnx</span></span></code></pre></div></li><li>이 <code>yolov5s_sim.onnx</code>를 RKNN 변환기에 넣어야 에러가 안 납니다.</li></ul></li><li><p><strong>입력 사이즈 불일치</strong></p><ul><li>ONNX 모델을 만들 때 <code>640x640</code>으로 만들었다면, 추론할 때도, <code>config</code> 할 때도 이미지가 무조건 <code>640x640</code>이어야 합니다.</li></ul></li></ol><h2 id="양자화-quantization-를-하는-이유" tabindex="-1">양자화(Quantization)를 하는 이유 <a class="header-anchor" href="#양자화-quantization-를-하는-이유" aria-label="Permalink to “양자화(Quantization)를 하는 이유”">​</a></h2><p><strong>양자화(Quantization)</strong>를 하는 가장 큰 이유는 <strong>&quot;압도적인 속도&quot;</strong>와 <strong>&quot;효율성&quot;</strong> 때문입니다.</p><p>특히 Rockchip NPU(RK3588 등)와 같은 엣지 디바이스(Edge Device) 환경에서는 선택이 아니라 <strong>거의 필수</strong>에 가깝습니다. 그 이유를 쉽게 비유와 기술적 사실로 나누어 설명해 드릴게요.</p><h3 id="_1-쉬운-비유-복잡한-계산-vs-어림잡기" tabindex="-1">1. 쉬운 비유: &quot;복잡한 계산 vs 어림잡기&quot; <a class="header-anchor" href="#_1-쉬운-비유-복잡한-계산-vs-어림잡기" aria-label="Permalink to “1. 쉬운 비유: &quot;복잡한 계산 vs 어림잡기&quot;”">​</a></h3><ul><li><strong>양자화를 안 한 것 (FP32)</strong>: <ul><li>질문: &quot;이 물건 가격이 얼마야?&quot;</li><li>대답: &quot;12,345.678912 원이야.&quot; (너무 정밀해서 계산이 오래 걸림)</li></ul></li><li><strong>양자화를 한 것 (INT8)</strong>: <ul><li>질문: &quot;이 물건 가격이 얼마야?&quot;</li><li>대답: &quot;대충 12,300원이야.&quot; (정확도는 약간 떨어지지만, 계산이 엄청나게 빠름)</li></ul></li></ul><p>AI가 &quot;이 사진이 고양이인가?&quot;를 판단할 때, <code>0.9998234</code>의 확률로 맞추나 <code>0.99</code>로 맞추나 결과는 똑같이 <strong>&quot;고양이&quot;</strong>입니다. 굳이 불필요하게 정밀한 소수점 계산을 하느라 힘을 뺄 필요가 없다는 것이 핵심 아이디어입니다.</p><h3 id="_2-기술적인-이유-3가지" tabindex="-1">2. 기술적인 이유 3가지 <a class="header-anchor" href="#_2-기술적인-이유-3가지" aria-label="Permalink to “2. 기술적인 이유 3가지”">​</a></h3><h4 id="_1-속도-speed-npu는-정수-integer-를-좋아해" tabindex="-1">① 속도 (Speed): NPU는 정수(Integer)를 좋아해 <a class="header-anchor" href="#_1-속도-speed-npu는-정수-integer-를-좋아해" aria-label="Permalink to “① 속도 (Speed): NPU는 정수(Integer)를 좋아해”">​</a></h4><p>Rockchip NPU 스펙표를 보면 <strong>&quot;6 TOPS&quot;</strong> 같은 성능 수치가 적혀있죠? 이 수치는 <strong>INT8(8비트 정수)</strong> 연산을 할 때 나오는 최대 성능입니다.</p><ul><li><strong>FP32 (소수점)</strong>: 32비트 데이터를 처리해야 하므로 계산이 복잡하고 느립니다.</li><li><strong>INT8 (정수)</strong>: 8비트 데이터만 처리하면 되므로, 한 번에 훨씬 많은 계산을 병렬로 처리할 수 있습니다.</li><li><strong>결과</strong>: 양자화를 하면 보통 <strong>2배에서 4배 이상</strong> 추론 속도(FPS)가 빨라집니다.</li></ul><h4 id="_2-용량-감소-model-size-1-4로-다이어트" tabindex="-1">② 용량 감소 (Model Size): 1/4로 다이어트 <a class="header-anchor" href="#_2-용량-감소-model-size-1-4로-다이어트" aria-label="Permalink to “② 용량 감소 (Model Size): 1/4로 다이어트”">​</a></h4><ul><li>일반적인 딥러닝 모델(FP32)은 하나의 숫자를 표현하는 데 <strong>4바이트(32비트)</strong>를 씁니다.</li><li>양자화(INT8)를 하면 <strong>1바이트(8비트)</strong>만 씁니다.</li><li>즉, 모델 파일의 크기가 정확히 <strong>1/4</strong>로 줄어듭니다. (예: 100MB 모델 → 25MB)</li><li>램(RAM)이 부족한 임베디드 보드에서는 메모리 절약이 매우 중요합니다.</li></ul><h4 id="_3-데이터-전송-효율-bandwidth" tabindex="-1">③ 데이터 전송 효율 (Bandwidth) <a class="header-anchor" href="#_3-데이터-전송-효율-bandwidth" aria-label="Permalink to “③ 데이터 전송 효율 (Bandwidth)”">​</a></h4><ul><li>NPU가 연산을 하려면 메모리에서 데이터를 가져와야 합니다.</li><li>데이터 크기가 작으니(1/4), 메모리에서 NPU로 데이터를 옮기는 속도도 훨씬 빨라집니다. 병목 현상이 줄어드는 것이죠.</li></ul><h3 id="_3-부작용은-없나요-trade-off" tabindex="-1">3. 부작용은 없나요? (Trade-off) <a class="header-anchor" href="#_3-부작용은-없나요-trade-off" aria-label="Permalink to “3. 부작용은 없나요? (Trade-off)”">​</a></h3><p>물론 공짜는 아닙니다. <strong>정확도(Accuracy)</strong>가 약간 떨어질 수 있습니다.</p><ul><li>소수점 10자리까지 있던 정밀한 값을 0~255 사이의 정수로 뭉뚱그리기 때문에 정보 손실이 발생합니다.</li><li><strong>하지만!</strong> 앞서 <code>convert.py</code> 코드에서 <strong><code>dataset.txt</code></strong>를 넣었던 것 기억하시나요? <ul><li>이 과정이 <strong>Calibration(보정)</strong>입니다.</li><li>샘플 이미지를 통해 &quot;어디서부터 어디까지의 값을 살리고, 어디를 버릴지&quot; 최적의 값을 찾기 때문에, 실제로는 <strong>정확도 하락이 1% 미만</strong>인 경우가 대부분입니다. 사람 눈으로는 차이를 못 느낄 정도죠.</li></ul></li></ul><h3 id="요약" tabindex="-1">요약 <a class="header-anchor" href="#요약" aria-label="Permalink to “요약”">​</a></h3><blockquote><p><strong>&quot;소수점 떼고 정수로 계산해서, 정확도는 아주 조금 희생하고 속도를 미친 듯이 올리기 위함&quot;</strong>입니다.</p></blockquote>`,50)])])}const c=i(t,[["render",h]]);export{g as __pageData,c as default};
